"""
æµå¼AIè·¯ç”±å™¨
æ”¯æŒæµå¼è°ƒç”¨OpenAIã€DeepSeekã€Geminiç­‰AIæä¾›å•†
ç”¨äºå®ç°å®æ—¶æ¨èè¿‡ç¨‹å±•ç¤º
"""
from typing import Literal, Optional, AsyncGenerator, Iterator
import os
import json
import asyncio
import aiohttp
from dotenv import load_dotenv
from pydantic import BaseModel

load_dotenv()

Provider = Literal["openai", "deepseek", "gemini"]

class StreamingAIRequest(BaseModel):
    prompt: str
    provider: Optional[Provider] = None
    model: Optional[str] = None
    temperature: Optional[float] = None
    api_key: Optional[str] = None
    stream: bool = True

class StreamingAIRouter:
    """æµå¼AIè·¯ç”±å™¨ï¼Œæ”¯æŒå®æ—¶æ•°æ®æµ"""
    
    def __init__(self):
        self.default_provider: Provider = os.getenv("DEFAULT_AI_PROVIDER", "deepseek")  # type: ignore
        
    def _get_temperature(self, temperature: Optional[float]) -> float:
        """è·å–æ¸©åº¦å‚æ•°ï¼Œå¸¦é»˜è®¤å€¼"""
        return temperature if temperature is not None else 0.3
    
    async def stream_complete(self, prompt: str, provider: Optional[Provider] = None, 
                             model: Optional[str] = None, temperature: Optional[float] = None, 
                             api_key: Optional[str] = None) -> AsyncGenerator[str, None]:
        """
        æµå¼å®ŒæˆAIè¯·æ±‚
        
        Args:
            prompt: æç¤ºè¯
            provider: AIæä¾›å•†
            model: æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°
            api_key: APIå¯†é’¥
            
        Yields:
            str: æµå¼è¿”å›çš„æ–‡æœ¬å—
        """
        provider = provider or self.default_provider
        
        print(f"ğŸ”„ å¼€å§‹æµå¼AIè¯·æ±‚ - Provider: {provider}, Model: {model}")
        
        try:
            if provider == "openai":
                async for chunk in self._openai_stream_complete(prompt, model, temperature, api_key):
                    yield chunk
            elif provider == "deepseek":
                async for chunk in self._deepseek_stream_complete(prompt, model, temperature, api_key):
                    yield chunk
            elif provider == "gemini":
                async for chunk in self._gemini_stream_complete(prompt, model, temperature, api_key):
                    yield chunk
            else:
                yield f"âŒ ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}"
                
        except Exception as e:
            yield f"âŒ AIæµå¼è¯·æ±‚å¤±è´¥: {str(e)}"
            
    async def _openai_stream_complete(self, prompt: str, model: Optional[str] = None, 
                                     temperature: Optional[float] = None, api_key: Optional[str] = None) -> AsyncGenerator[str, None]:
        """OpenAIæµå¼å®Œæˆ"""
        try:
            from openai import AsyncOpenAI
            
            key = api_key or os.getenv("OPENAI_API_KEY")
            if not key:
                yield "âŒ OpenAI API Key æœªé…ç½®"
                return
                
            client = AsyncOpenAI(api_key=key)
            mdl = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")
            temp = self._get_temperature(temperature)
            
            stream = await client.chat.completions.create(
                model=mdl,
                messages=[{"role": "user", "content": prompt}],
                temperature=temp,
                stream=True
            )
            
            async for chunk in stream:
                content = chunk.choices[0].delta.content
                if content:
                    yield content
                    
        except Exception as e:
            yield f"âŒ OpenAIæµå¼è¯·æ±‚å¤±è´¥: {str(e)}"
    
    async def _deepseek_stream_complete(self, prompt: str, model: Optional[str] = None, 
                                       temperature: Optional[float] = None, api_key: Optional[str] = None) -> AsyncGenerator[str, None]:
        """DeepSeekæµå¼å®Œæˆ"""
        try:
            key = api_key or os.getenv("DEEPSEEK_API_KEY")
            base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
            mdl = model or os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
            
            if not key:
                yield "âŒ DeepSeek API Key æœªé…ç½®"
                return
                
            url = f"{base_url}/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {key}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": mdl,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": self._get_temperature(temperature),
                "stream": True
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, headers=headers) as response:
                    if response.status != 200:
                        yield f"âŒ DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status}"
                        return
                        
                    async for line in response.content:
                        line_str = line.decode('utf-8').strip()
                        if line_str.startswith('data: '):
                            data_str = line_str[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                            
                            if data_str == '[DONE]':
                                break
                                
                            try:
                                data = json.loads(data_str)
                                content = data.get('choices', [{}])[0].get('delta', {}).get('content')
                                if content:
                                    yield content
                            except json.JSONDecodeError:
                                continue
                                
        except Exception as e:
            yield f"âŒ DeepSeekæµå¼è¯·æ±‚å¤±è´¥: {str(e)}"
    
    async def _gemini_stream_complete(self, prompt: str, model: Optional[str] = None, 
                                     temperature: Optional[float] = None, api_key: Optional[str] = None) -> AsyncGenerator[str, None]:
        """Geminiæµå¼å®Œæˆ"""
        try:
            import google.generativeai as genai
            
            key = api_key or os.getenv("GEMINI_API_KEY")
            if not key:
                yield "âŒ Gemini API Key æœªé…ç½®"
                return
                
            genai.configure(api_key=key)
            mdl = model or os.getenv("GEMINI_MODEL", "gemini-pro")
            model_obj = genai.GenerativeModel(mdl)
            
            generation_config = {
                "temperature": self._get_temperature(temperature)
            }
            
            # Geminiçš„æµå¼æ¥å£ä½¿ç”¨æ–¹å¼
            response = model_obj.generate_content(
                prompt, 
                generation_config=generation_config,
                stream=True
            )
            
            for chunk in response:
                if chunk.text:
                    yield chunk.text
                    
        except Exception as e:
            yield f"âŒ Geminiæµå¼è¯·æ±‚å¤±è´¥: {str(e)}"
    
    async def complete_sync(self, req: StreamingAIRequest) -> str:
        """
        åŒæ­¥æ–¹å¼å®ŒæˆAIè¯·æ±‚ï¼ˆå…¼å®¹åŸæœ‰æ¥å£ï¼‰
        """
        full_response = ""
        async for chunk in self.stream_complete(
            req.prompt, req.provider, req.model, req.temperature, req.api_key
        ):
            full_response += chunk
        return full_response
    
    def complete_sync_blocking(self, req: StreamingAIRequest) -> str:
        """
        é˜»å¡å¼åŒæ­¥å®ŒæˆAIè¯·æ±‚ï¼ˆå…¼å®¹åŸæœ‰éå¼‚æ­¥ä»£ç ï¼‰
        """
        try:
            # åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # åˆ›å»ºæ–°çš„ä»»åŠ¡
                task = asyncio.create_task(self.complete_sync(req))
                return asyncio.run_coroutine_threadsafe(self.complete_sync(req), loop).result()
            else:
                return asyncio.run(self.complete_sync(req))
        except RuntimeError:
            # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
            return asyncio.run(self.complete_sync(req))

class ProgressManager:
    """ä»»åŠ¡è¿›åº¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.progress_callbacks = {}
        
    def register_callback(self, task_id: str, callback):
        """æ³¨å†Œè¿›åº¦å›è°ƒå‡½æ•°"""
        self.progress_callbacks[task_id] = callback
        
    def unregister_callback(self, task_id: str):
        """æ³¨é”€è¿›åº¦å›è°ƒå‡½æ•°"""
        if task_id in self.progress_callbacks:
            del self.progress_callbacks[task_id]
    
    async def update_progress(self, task_id: str, progress: float):
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        if task_id in self.progress_callbacks:
            try:
                await self.progress_callbacks[task_id]({
                    'type': 'progress',
                    'task_id': task_id,
                    'progress': progress,
                    'timestamp': asyncio.get_event_loop().time()
                })
            except Exception as e:
                print(f"âŒ è¿›åº¦å›è°ƒå¤±è´¥: {e}")
    
    async def update_current_symbol(self, task_id: str, symbol: str):
        """æ›´æ–°å½“å‰å¤„ç†çš„è‚¡ç¥¨"""
        if task_id in self.progress_callbacks:
            try:
                await self.progress_callbacks[task_id]({
                    'type': 'current_symbol',
                    'task_id': task_id,
                    'symbol': symbol,
                    'timestamp': asyncio.get_event_loop().time()
                })
            except Exception as e:
                print(f"âŒ ç¬¦å·æ›´æ–°å›è°ƒå¤±è´¥: {e}")
    
    async def push_ai_chunk(self, task_id: str, symbol: str, chunk: str, accumulated: str):
        """æ¨é€AIæ•°æ®å—"""
        if task_id in self.progress_callbacks:
            try:
                await self.progress_callbacks[task_id]({
                    'type': 'ai_chunk',
                    'task_id': task_id,
                    'symbol': symbol,
                    'chunk': chunk,
                    'accumulated': accumulated,
                    'timestamp': asyncio.get_event_loop().time()
                })
            except Exception as e:
                print(f"âŒ AIå—æ¨é€å›è°ƒå¤±è´¥: {e}")
    
    async def record_symbol_completed(self, task_id: str, symbol: str):
        """è®°å½•è‚¡ç¥¨åˆ†æå®Œæˆ"""
        if task_id in self.progress_callbacks:
            try:
                await self.progress_callbacks[task_id]({
                    'type': 'symbol_completed',
                    'task_id': task_id,
                    'symbol': symbol,
                    'timestamp': asyncio.get_event_loop().time()
                })
            except Exception as e:
                print(f"âŒ å®Œæˆè®°å½•å›è°ƒå¤±è´¥: {e}")
    
    async def record_symbol_failed(self, task_id: str, symbol: str, error: str):
        """è®°å½•è‚¡ç¥¨åˆ†æå¤±è´¥"""
        if task_id in self.progress_callbacks:
            try:
                await self.progress_callbacks[task_id]({
                    'type': 'symbol_failed',
                    'task_id': task_id,
                    'symbol': symbol,
                    'error': error,
                    'timestamp': asyncio.get_event_loop().time()
                })
            except Exception as e:
                print(f"âŒ å¤±è´¥è®°å½•å›è°ƒå¤±è´¥: {e}")
                
    async def update_phase(self, task_id: str, phase: str):
        """æ›´æ–°ä»»åŠ¡é˜¶æ®µ"""
        if task_id in self.progress_callbacks:
            try:
                await self.progress_callbacks[task_id]({
                    'type': 'phase_change',
                    'task_id': task_id,
                    'phase': phase,
                    'timestamp': asyncio.get_event_loop().time()
                })
            except Exception as e:
                print(f"âŒ é˜¶æ®µæ›´æ–°å›è°ƒå¤±è´¥: {e}")
    
    async def record_ai_analysis_start(self, task_id: str, symbol: str):
        """è®°å½•AIåˆ†æå¼€å§‹"""
        if task_id in self.progress_callbacks:
            try:
                await self.progress_callbacks[task_id]({
                    'type': 'ai_analysis_start',
                    'task_id': task_id,
                    'symbol': symbol,
                    'timestamp': asyncio.get_event_loop().time()
                })
            except Exception as e:
                print(f"âŒ AIåˆ†æå¼€å§‹å›è°ƒå¤±è´¥: {e}")
    
    async def record_symbol_analysis_complete(self, task_id: str, symbol: str, result: dict):
        """è®°å½•è‚¡ç¥¨åˆ†æå®Œæˆ"""
        if task_id in self.progress_callbacks:
            try:
                await self.progress_callbacks[task_id]({
                    'type': 'symbol_analysis_complete',
                    'task_id': task_id,
                    'symbol': symbol,
                    'result': result,
                    'timestamp': asyncio.get_event_loop().time()
                })
            except Exception as e:
                print(f"âŒ åˆ†æå®Œæˆå›è°ƒå¤±è´¥: {e}")

# å…¨å±€è¿›åº¦ç®¡ç†å™¨å®ä¾‹
progress_manager = ProgressManager()